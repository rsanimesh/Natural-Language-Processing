{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text classification using  Naive Bayes classifier\n",
    "In this notebook we will\n",
    "1. Load sklearn 20newsgroups dataset\n",
    "2.  Create Model using pipeline containing two components, count vectorizer and naive bayes classifier\n",
    "3.  Save, load and test the model/pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "Below are installation instruction of libraries requeried for this notebook\n",
    "\n",
    "> * !pip install -U scikit-learn\n",
    "* !pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "\n",
    "# import for dataset from sklearn\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# import for feature creation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# import algorithms\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# import for creating pipelines\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# import for saving and loading model file\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the 20 newsgroups dataset form sklean libariry\n",
    "label_categories = ['alt.atheism', 'soc.religion.christian','comp.graphics', 'sci.med']\n",
    "train_data = fetch_20newsgroups(subset='train', categories=label_categories, shuffle=True, random_state=42)\n",
    "test_data = fetch_20newsgroups(subset='test', categories=label_categories, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Number:  1\n",
      "Label Name:  alt.atheism\n",
      "\n",
      "Text:\n",
      "\n",
      "From: sd345@city.ac.uk (Michael Collier)\n",
      "Subject: Converting images to HP LaserJet III?\n",
      "Nntp-Posting-Host: hampton\n",
      "Organization: The City University\n",
      "Lines: 14\n",
      "\n",
      "Does anyone know of a good way (standard PC application/PD utility) to\n",
      "convert tif/img/tga files into LaserJet III format.  We would also like to\n",
      "do the same, converting to HPGL (HP plotter) files.\n",
      "\n",
      "Please email any response.\n",
      "\n",
      "Is this the correct group?\n",
      "\n",
      "Thanks in advance.  Michael.\n",
      "-- \n",
      "Michael Collier (Programmer)                 The Computer Unit,\n",
      "Email: M.P.Collier@uk.ac.city                The City University,\n",
      "Tel: 071 477-8000 x3769                      London,\n",
      "Fax: 071 477-8565                            EC1V 0HB.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# priniting sample data\n",
    "print(\"Label Number: \",train_data.target[0])\n",
    "print(\"Label Name: \",train_data.target_names[0])\n",
    "print(\"\\nText:\\n\")\n",
    "print(train_data.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with Pipeline\n",
    "\n",
    "We are creating a pipeline consists of two components, vectorizer and classifier.\n",
    "\n",
    "The output of first is input for next component `vectorizer => classifier`.\n",
    "\n",
    "1. CountVectorizer(vectorizer) converts text data into numbers using `Bag Of Words` methodology. It includes Text preprocessing, tokenizing and filtering of stopwords.\n",
    "\n",
    "\n",
    "2. MultinomialNB() is a na√Øve Bayes classifier which predict the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating model pipeline\n",
    "model = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(stop_words=\"english\")),\n",
    "    ('classifier', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)), ('classifier', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training model pipeline\n",
    "model.fit(train_data.data, train_data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9420772303595206\n"
     ]
    }
   ],
   "source": [
    "# testing over test data\n",
    "predicted = model.predict(test_data.data)\n",
    "print(\"Accuracy: \",np.mean(predicted == test_data.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and loading the model file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['naive_bayes_model']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(model, 'naive_bayes_model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes_model = load('naive_bayes_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"Does anyone know of a good way (standard PC application/PD utility) to\n",
    "convert tif/img/tga files into LaserJet III format.  We would also like to\n",
    "do the same, converting to HPGL (HP plotter) files.\"\"\"\n",
    "\n",
    "predicted_value = naive_bayes_model.predict([text])\n",
    "predicted_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Number:  1\n",
      "Predicted Class:  comp.graphics\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted Number: \",predicted_value[0])\n",
    "print(\"Predicted Class: \",train_data.target_names[predicted_value[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reference - https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
